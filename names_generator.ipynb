{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db00378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f79343",
   "metadata": {},
   "source": [
    "### Information\n",
    "- We will do a few preliminary exercises and also build a character level MLP language model.\n",
    "- This model will be similar to the model we did in class, except that we will have characters as tokens, not words.\n",
    "- You will need a conda environment for this, here is general information on this.\n",
    " - https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html\n",
    " - PyTorch: https://anaconda.org/pytorch/pytorch\n",
    " \n",
    "In the code below, FILL-IN the code necessary in the hint string provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb873f",
   "metadata": {},
   "source": [
    "### Preliminary exercises\n",
    "- Please fill in the cells below with the asked for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a23f069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1dab7f4ca70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f91a6ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# Create an embedding layer for a vocabulary of size 10 and the word vectors are each of dimension 5.\n",
    "e = nn.Embedding(10, 5)\n",
    "\n",
    "# Extract the embedding for the word whose token index is 3. What is the shape of this vector?\n",
    "v = e(torch.tensor(3)) # should be a vector of size 5\n",
    "print(v.shape)\n",
    "\n",
    "# Extract the weight matrix from the layer e.\n",
    "w = e.weight\n",
    "# Create a linear layer (with no bias) of size 10 by 5 and set it's data to the embedding matrix.\n",
    "l = nn.Linear(10, 5)\n",
    "l.weight = w\n",
    "\n",
    "# Insert inside of the assert below some sort of equality check between l.weight and e.weight; it should pass to true.\n",
    "# Hint: look up torch.all() and torch.eq()\n",
    "assert(torch.all(torch.eq(l.weight, e.weight)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37fec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch of size 2 with entries [0, 1, 2] and [2, 3, 4] in the data batch.\n",
    "x = torch.tensor([\n",
    "    [0, 1, 2],\n",
    "    [2, 3, 4]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f3a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the dimension of this batch ran through the embeding layer?\n",
    "# e will tranform each integer to a vector of size 5. So we hould expect an output of size (2, 3, 5)\n",
    "assert(e(x).shape == torch.Size([2, 3, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9140e3c",
   "metadata": {},
   "source": [
    "### Constants and configs used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ace94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\"\n",
    "LR = 4.0\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 5\n",
    "MARKER = '.'\n",
    "# N-gram level; P(w_t | w_{t-1}, ..., w_{t-n+1}).\n",
    "# We use 3 words to predict the next word.\n",
    "n = 4\n",
    "# Hidden layer dimension.\n",
    "h = 20\n",
    "# Word embedding dimension.\n",
    "m = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f16039",
   "metadata": {},
   "source": [
    "### Get the dataset and the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4dca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, words, chars):\n",
    "        self.words = words\n",
    "        self.chars = chars\n",
    "        # Inverse dictionaries mapping char tokens to unique ids and the reverse.\n",
    "        # Tokens in this case are the unique chars we passed in above.\n",
    "        # Each token should be mappend to a unique integer and MARKER should have token 0.\n",
    "        # For example, stoi should be like {'.' -> 0, 'a' -> 1, 'b' -> 2} if I pass in chars = '.ab'.\n",
    "        self.stoi = {c:i for (c, i) in zip(chars, range(len(chars)))}\n",
    "        self.itos = {i:c for (c, i) in self.stoi.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of words.\n",
    "        return len(self.words)\n",
    "\n",
    "    def contains(self, word):\n",
    "        # Check if word is in self.words and return True/False if it is, is not.\n",
    "        return (word in self.words)\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        # Return the vocabulary size.\n",
    "        return len(set(self.words))\n",
    "\n",
    "    def encode(self, word):\n",
    "        # Express this word as a list of int ids. For example, maybe \".abc\" -> [0, 1, 2, 3].\n",
    "        # This assumes 'a' -> 1, etc.\n",
    "        return [self.stoi[c] for c in word]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        # For a set of tokens, return back the string.\n",
    "        # For example, maybe [1, 1, 2] -> \"aac\"\n",
    "        return ''.join([self.itos[i] for i in tokens])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # This is used so we can loop over the data.\n",
    "        word = self.words[idx]\n",
    "        return self.encode(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e480ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(window, input_file = 'names.txt'):\n",
    "    \"\"\"\n",
    "    This takes a file of words and separates all the words.\n",
    "    It then gets all the characters present in the universe of words and then ouputs the statistics. \n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = f.read()\n",
    "    # Split the file by new lines. You should get a list of names.\n",
    "    words = data.split('\\n')\n",
    "    words = [w.strip() for w in words] # This gets rid of any trailing and starting white spaces.\n",
    "    words = [w for w in words if w != ''] # Filter out all the empty words.\n",
    "    \n",
    "    chars = sorted(list(set(''.join(words)))) # This gets the universe of all characters.\n",
    "    \n",
    "    # Will force chars to have MARKER having index 0.\n",
    "    chars= [MARKER] + chars\n",
    "    \n",
    "    # Pad each word with a context window of size n-1.\n",
    "    # Why? a word like \"abc\" should becomes \"..abc..\" if the window is size 3.\n",
    "    # This is some we can get pair of (x, y) data like this: \"..\" -> \"a\", \".a\" -> \"b\", \"ab\" -> \"c\", \"bc\" -> \".\", \"c.\" -> \".\"\n",
    "    # I.e. this allows us to know that \"a\" is a start character.\n",
    "    # So you should get something like [\"ab\", \"c\"] -> [\"..ab..\", \"..c..\"], for example.\n",
    "    words = ['.' * (window - 1) + w + '.' * (window - 1) for w in words]\n",
    "            \n",
    "    print(f\"The number of examples in the dataset: {len(words)}\")\n",
    "    print(f\"The number of unique characters in the vocabulary: {len(chars)}\")\n",
    "    print(f\"The vocabulary we have is: {''.join(chars)}\")\n",
    "\n",
    "    # Partition the input data into a training, validation, and the test set.\n",
    "    out_of_sample_set_size = min(2000, int(len(words) * 0.1)) # We use 10% of the training set, or up to 2000 examples.\n",
    "    test_set_size = 1500\n",
    "    \n",
    "    # First, get a random permutation of randomly permute of size len(words).\n",
    "    # Then, convert this to a list. \n",
    "    # This index list is used below to get the train, validation, and test sets.\n",
    "    rp = torch.randperm(len(words)).tolist()\n",
    "    \n",
    "    # Get train, validation, and test set.\n",
    "    train_words = [words[i] for i in rp[:-out_of_sample_set_size]]\n",
    "    validation_words = [words[i] for i in rp[-out_of_sample_set_size:-test_set_size]]\n",
    "    test_words = [words[i] for i in rp[-test_set_size:]]    \n",
    "    \n",
    "    print(f\"We've split up the dataset into {len(train_words)}, {len(validation_words)}, {len(test_words)} training, validation, and test examples\")\n",
    "\n",
    "    # But the data in the data set objects.\n",
    "    train_dataset = CharDataset(train_words, chars)\n",
    "    validation_dataset = CharDataset(validation_words, chars)\n",
    "    test_dataset = CharDataset(test_words, chars)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b97647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of examples in the dataset: 32033\n",
      "The number of unique characters in the vocabulary: 27\n",
      "The vocabulary we have is: .abcdefghijklmnopqrstuvwxyz\n",
      "We've split up the dataset into 30033, 500, 1500 training, validation, and test examples\n"
     ]
    }
   ],
   "source": [
    "train_dataset, validation_dataset, test_dataset = create_datasets(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b45bc",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6cb698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...zaliya...'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first word in \"train_dataset\"\n",
    "train_dataset.words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8369b489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "It has 27 keys\n"
     ]
    }
   ],
   "source": [
    "# Get the stoi map of train_dataset. How many keys does it have?\n",
    "print(train_dataset.stoi)\n",
    "print(f'It has {len(train_dataset.stoi.keys())} keys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4881fe",
   "metadata": {},
   "source": [
    "### Get the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7967c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, window):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    # For ech word.\n",
    "    for i, word in enumerate(dataset):\n",
    "        # Grab a context of size window and window-1 characters will be in x, 1 will be in y.\n",
    "        for j, _ in enumerate(word):\n",
    "            # If there is no window of size window left, break.\n",
    "            if j + window > len(word) - 1:\n",
    "                break\n",
    "            word_window = word[j:j + window + 1]\n",
    "            x, y = word_window[:-1], word_window[-1]\n",
    "            x_list.append(x)\n",
    "            y_list.append(y)\n",
    "            \n",
    "    return DataLoader(\n",
    "        TensorDataset(torch.tensor(x_list), torch.tensor(y_list)),\n",
    "        BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5086d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(train_dataset, n-1)\n",
    "validation_dataloader = create_dataloader(validation_dataset, n-1)\n",
    "test_dataloader = create_dataloader(test_dataset, n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca51b36",
   "metadata": {},
   "source": [
    "### Set up the model\n",
    "- Identical to lecture. Please look over that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab8cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the first Neural language models!\n",
    "class CharacterNeuralLanguageModel(nn.Module):\n",
    "    def __init__(self, V, m, h, n):\n",
    "        super(CharacterNeuralLanguageModel, self).__init__()\n",
    "        \n",
    "        # Vocabulary size.\n",
    "        self.V = V\n",
    "        \n",
    "        # Embedding dimension, per word.\n",
    "        self.m = m\n",
    "        \n",
    "        # Hidden dimension.\n",
    "        self.h = h\n",
    "        \n",
    "        # N in \"N-gram\"\n",
    "        self.n = n\n",
    "        print(n)\n",
    "        \n",
    "        # Can you change all this stuff to use nn.Linear?\n",
    "        # Ca also use nn.Parameter(torch.zeros(V, m)) for self.C but then we need one-hot and this is slow.\n",
    "        self.C = nn.Embedding(V, m) \n",
    "        self.H = nn.Parameter(torch.zeros((n-1) * m, h))\n",
    "        self.W = nn.Parameter(torch.zeros((n-1) * m, V))\n",
    "        self.U = nn.Parameter(torch.zeros(h, V))\n",
    "        \n",
    "        self.b = torch.nn.Parameter(torch.ones(V))\n",
    "        self.d = torch.nn.Parameter(torch.ones(h))\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # Intitialize C, H, W, U in a nice way. Use xavier initialization for the weights.\n",
    "        # On a first run, just pass.\n",
    "        nn.init.xavier_uniform_(self.C.weight)\n",
    "        nn.init.xavier_uniform_(self.H)\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        nn.init.xavier_uniform_(self.U)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x is of dimenson N = batch size X n-1\n",
    "        \n",
    "        # N X (n-1) X m \n",
    "        x = self.C(x)\n",
    "        \n",
    "        # N\n",
    "        B = x.shape[0]\n",
    "        \n",
    "        # N X (n-1) * m\n",
    "        x = x.view(B, -1)\n",
    "    \n",
    "        # N X V\n",
    "        y = self.b + torch.matmul(x, self.W) + torch.matmul(nn.Tanh()(self.d + torch.matmul(x, self.H)), self.U)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899045e6",
   "metadata": {},
   "source": [
    "### Set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b8e0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Identical to lecture.\n",
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "model = CharacterNeuralLanguageModel(\n",
    "    train_dataset.get_vocab_size(), m, h, n\n",
    ").to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10508c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2812151 parameters in the model\n"
     ]
    }
   ],
   "source": [
    "# How many parameters does the neural network have?\n",
    "# Hint: look up model.named_parameters and the method \"nelement\" on a tensor.\n",
    "# See also the XOR notebook where we count the gradients that are 0.\n",
    "# There, we loop over the parameters.\n",
    "number_parameters = sum([param.nelement() for _, param in model.named_parameters()])\n",
    "print(f'There are {number_parameters} parameters in the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b5bb91",
   "metadata": {},
   "source": [
    "### Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e49ebc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(total_loss, total_batches):\n",
    "    return torch.exp(torch.tensor(total_loss / total_batches)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d58cc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_batches = 0.0, 0.0\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(x)\n",
    "                        \n",
    "        # Get the loss.\n",
    "        loss = criterion(input=logits, target=y.squeeze(-1))\n",
    "\n",
    "        # Do back propagation.\n",
    "        loss.backward()\n",
    "                        \n",
    "        # Clip the gradients so they don't explode. Look at how this is done in lecture.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        \n",
    "        # Do an optimization step.\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "                \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            perplexity = calculate_perplexity(total_loss,  total_batches)\n",
    "            print(\n",
    "                \"| epoch {:3d} \"\n",
    "                \"| {:5d}/{:5d} batches \"\n",
    "                \"| perplexity {:8.3f} \"\n",
    "                \"| loss {:8.3f} \"\n",
    "                .format(\n",
    "                    epoch,\n",
    "                    idx,\n",
    "                    len(dataloader),\n",
    "                    perplexity,\n",
    "                    total_loss / total_batches,\n",
    "                )\n",
    "            )\n",
    "            total_loss, total_batches = 0.0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85722617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_batches = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(dataloader):\n",
    "            logits = model(x)\n",
    "            total_loss += criterion(input=logits, target=y.squeeze(-1)).item()\n",
    "            total_batches += 1\n",
    "    return total_loss / total_batches, calculate_perplexity(total_loss,  total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21ba24f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [00:12, 42.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/17123 batches | perplexity   12.394 | loss    2.517 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1006it [00:26, 37.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/17123 batches | perplexity    7.784 | loss    2.052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1507it [00:39, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1500/17123 batches | perplexity    7.436 | loss    2.006 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2005it [00:52, 39.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2000/17123 batches | perplexity    7.357 | loss    1.996 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2505it [01:04, 40.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2500/17123 batches | perplexity    6.886 | loss    1.929 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3008it [01:16, 43.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  3000/17123 batches | perplexity    6.971 | loss    1.942 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3509it [01:29, 42.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  3500/17123 batches | perplexity    6.912 | loss    1.933 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4006it [01:41, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  4000/17123 batches | perplexity    6.794 | loss    1.916 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4508it [01:54, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  4500/17123 batches | perplexity    6.949 | loss    1.939 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5005it [02:07, 40.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  5000/17123 batches | perplexity    6.886 | loss    1.929 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5509it [02:20, 41.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  5500/17123 batches | perplexity    6.763 | loss    1.912 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6004it [02:32, 42.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  6000/17123 batches | perplexity    6.921 | loss    1.935 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6507it [02:44, 41.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  6500/17123 batches | perplexity    6.633 | loss    1.892 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7009it [02:56, 41.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  7000/17123 batches | perplexity    6.703 | loss    1.903 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7506it [03:08, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  7500/17123 batches | perplexity    6.392 | loss    1.855 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8007it [03:21, 38.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  8000/17123 batches | perplexity    6.312 | loss    1.842 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8509it [03:34, 41.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  8500/17123 batches | perplexity    6.569 | loss    1.882 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9005it [03:46, 41.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  9000/17123 batches | perplexity    6.411 | loss    1.858 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9508it [03:59, 42.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  9500/17123 batches | perplexity    6.569 | loss    1.882 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10008it [04:11, 41.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 10000/17123 batches | perplexity    6.427 | loss    1.860 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10507it [04:23, 39.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 10500/17123 batches | perplexity    6.454 | loss    1.865 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11009it [04:36, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 11000/17123 batches | perplexity    6.275 | loss    1.837 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11509it [04:49, 41.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 11500/17123 batches | perplexity    6.462 | loss    1.866 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12008it [05:01, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 12000/17123 batches | perplexity    6.326 | loss    1.845 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12508it [05:15, 39.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 12500/17123 batches | perplexity    6.418 | loss    1.859 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13008it [05:28, 39.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 13000/17123 batches | perplexity    6.524 | loss    1.876 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13506it [05:41, 26.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 13500/17123 batches | perplexity    6.403 | loss    1.857 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14005it [05:56, 37.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 14000/17123 batches | perplexity    6.361 | loss    1.850 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14509it [06:10, 38.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 14500/17123 batches | perplexity    6.483 | loss    1.869 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15006it [06:23, 41.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 15000/17123 batches | perplexity    6.267 | loss    1.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15504it [06:35, 36.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 15500/17123 batches | perplexity    6.249 | loss    1.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16006it [06:48, 40.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 16000/17123 batches | perplexity    6.341 | loss    1.847 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16504it [07:00, 40.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 16500/17123 batches | perplexity    6.333 | loss    1.846 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17007it [07:12, 40.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 17000/17123 batches | perplexity    6.264 | loss    1.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17123it [07:15, 39.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 438.14s | valid perplexity    6.260 | valid loss    1.834\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "506it [00:13, 39.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |   500/17123 batches | perplexity    5.919 | loss    1.778 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1007it [00:28, 39.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1000/17123 batches | perplexity    5.911 | loss    1.777 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1506it [00:41, 38.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1500/17123 batches | perplexity    5.854 | loss    1.767 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2007it [00:55, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2000/17123 batches | perplexity    5.850 | loss    1.766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2508it [01:07, 38.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2500/17123 batches | perplexity    5.747 | loss    1.749 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3006it [01:20, 40.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  3000/17123 batches | perplexity    5.562 | loss    1.716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3506it [01:34, 37.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  3500/17123 batches | perplexity    5.875 | loss    1.771 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4004it [01:48, 35.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  4000/17123 batches | perplexity    5.621 | loss    1.726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4506it [02:01, 40.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  4500/17123 batches | perplexity    5.780 | loss    1.754 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5009it [02:14, 40.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  5000/17123 batches | perplexity    5.825 | loss    1.762 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5504it [02:26, 41.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  5500/17123 batches | perplexity    5.829 | loss    1.763 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6006it [02:38, 41.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  6000/17123 batches | perplexity    5.711 | loss    1.742 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6507it [02:50, 40.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  6500/17123 batches | perplexity    5.988 | loss    1.790 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7008it [03:03, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  7000/17123 batches | perplexity    5.762 | loss    1.751 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7508it [03:15, 42.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  7500/17123 batches | perplexity    5.758 | loss    1.751 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8005it [03:27, 40.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  8000/17123 batches | perplexity    5.655 | loss    1.733 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8508it [03:39, 40.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  8500/17123 batches | perplexity    5.605 | loss    1.724 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9009it [03:51, 43.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  9000/17123 batches | perplexity    5.796 | loss    1.757 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9504it [04:03, 40.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  9500/17123 batches | perplexity    5.779 | loss    1.754 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10007it [04:16, 41.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 10000/17123 batches | perplexity    5.834 | loss    1.764 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10504it [04:28, 40.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 10500/17123 batches | perplexity    5.801 | loss    1.758 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11004it [04:40, 41.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 11000/17123 batches | perplexity    5.818 | loss    1.761 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11506it [04:53, 41.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 11500/17123 batches | perplexity    5.760 | loss    1.751 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12005it [05:05, 39.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 12000/17123 batches | perplexity    5.811 | loss    1.760 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12506it [05:18, 40.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 12500/17123 batches | perplexity    5.576 | loss    1.719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13005it [05:30, 41.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 13000/17123 batches | perplexity    5.743 | loss    1.748 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13504it [05:43, 39.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 13500/17123 batches | perplexity    5.669 | loss    1.735 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14005it [05:55, 36.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 14000/17123 batches | perplexity    5.687 | loss    1.738 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14509it [06:09, 38.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 14500/17123 batches | perplexity    5.688 | loss    1.738 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15005it [06:21, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 15000/17123 batches | perplexity    5.659 | loss    1.733 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15509it [06:34, 41.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 15500/17123 batches | perplexity    5.457 | loss    1.697 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16008it [06:46, 41.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 16000/17123 batches | perplexity    5.726 | loss    1.745 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16505it [06:58, 40.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 16500/17123 batches | perplexity    5.563 | loss    1.716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17009it [07:11, 40.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | 17000/17123 batches | perplexity    5.686 | loss    1.738 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17123it [07:13, 39.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 436.45s | valid perplexity    5.719 | valid loss    1.744\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505it [00:12, 40.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |   500/17123 batches | perplexity    5.728 | loss    1.745 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1005it [00:24, 39.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1000/17123 batches | perplexity    5.580 | loss    1.719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1507it [00:37, 41.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1500/17123 batches | perplexity    5.844 | loss    1.765 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2006it [00:49, 40.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  2000/17123 batches | perplexity    5.689 | loss    1.739 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2505it [01:01, 42.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  2500/17123 batches | perplexity    5.730 | loss    1.746 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3007it [01:14, 39.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  3000/17123 batches | perplexity    5.517 | loss    1.708 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3509it [01:26, 41.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  3500/17123 batches | perplexity    5.738 | loss    1.747 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4004it [01:38, 41.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  4000/17123 batches | perplexity    5.645 | loss    1.731 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4509it [01:51, 41.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  4500/17123 batches | perplexity    5.686 | loss    1.738 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5009it [02:03, 41.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  5000/17123 batches | perplexity    5.617 | loss    1.726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5509it [02:16, 41.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  5500/17123 batches | perplexity    5.472 | loss    1.700 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6005it [02:28, 39.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  6000/17123 batches | perplexity    5.715 | loss    1.743 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6509it [02:41, 39.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  6500/17123 batches | perplexity    5.692 | loss    1.739 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7006it [02:53, 43.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  7000/17123 batches | perplexity    5.544 | loss    1.713 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7504it [03:05, 39.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  7500/17123 batches | perplexity    5.575 | loss    1.718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8006it [03:18, 41.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  8000/17123 batches | perplexity    5.636 | loss    1.729 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8507it [03:30, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  8500/17123 batches | perplexity    5.571 | loss    1.718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9007it [03:43, 41.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  9000/17123 batches | perplexity    5.864 | loss    1.769 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9505it [03:55, 39.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  9500/17123 batches | perplexity    5.684 | loss    1.738 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10004it [04:07, 39.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 10000/17123 batches | perplexity    5.632 | loss    1.728 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10506it [04:19, 40.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 10500/17123 batches | perplexity    5.562 | loss    1.716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11005it [04:32, 39.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 11000/17123 batches | perplexity    5.734 | loss    1.746 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11507it [04:44, 40.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 11500/17123 batches | perplexity    5.654 | loss    1.732 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12007it [04:56, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 12000/17123 batches | perplexity    5.620 | loss    1.726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12506it [05:09, 40.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 12500/17123 batches | perplexity    5.786 | loss    1.756 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13006it [05:21, 40.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 13000/17123 batches | perplexity    5.460 | loss    1.697 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13507it [05:33, 42.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 13500/17123 batches | perplexity    5.739 | loss    1.747 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14009it [05:46, 41.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 14000/17123 batches | perplexity    5.618 | loss    1.726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14508it [05:58, 42.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 14500/17123 batches | perplexity    5.618 | loss    1.726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15006it [06:10, 41.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 15000/17123 batches | perplexity    5.616 | loss    1.726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15505it [06:23, 41.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 15500/17123 batches | perplexity    5.708 | loss    1.742 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16007it [06:35, 39.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 16000/17123 batches | perplexity    5.473 | loss    1.700 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16505it [06:47, 39.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 16500/17123 batches | perplexity    5.497 | loss    1.704 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17007it [06:59, 40.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | 17000/17123 batches | perplexity    5.637 | loss    1.729 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17123it [07:02, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 425.36s | valid perplexity    5.674 | valid loss    1.736\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "506it [00:12, 39.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |   500/17123 batches | perplexity    5.686 | loss    1.738 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1006it [00:24, 42.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1000/17123 batches | perplexity    5.431 | loss    1.692 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1508it [00:37, 40.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1500/17123 batches | perplexity    5.588 | loss    1.721 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2009it [00:49, 40.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  2000/17123 batches | perplexity    5.814 | loss    1.760 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2505it [01:01, 41.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  2500/17123 batches | perplexity    5.790 | loss    1.756 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3006it [01:14, 39.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  3000/17123 batches | perplexity    5.575 | loss    1.718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3506it [01:26, 40.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  3500/17123 batches | perplexity    5.614 | loss    1.725 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4004it [01:39, 34.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  4000/17123 batches | perplexity    5.549 | loss    1.714 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4509it [01:53, 37.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  4500/17123 batches | perplexity    5.727 | loss    1.745 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5006it [02:05, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  5000/17123 batches | perplexity    5.572 | loss    1.718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5508it [02:18, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  5500/17123 batches | perplexity    5.555 | loss    1.715 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6008it [02:30, 40.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  6000/17123 batches | perplexity    5.564 | loss    1.716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6504it [02:42, 36.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  6500/17123 batches | perplexity    5.695 | loss    1.740 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7008it [02:55, 39.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  7000/17123 batches | perplexity    5.672 | loss    1.735 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7507it [03:08, 39.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  7500/17123 batches | perplexity    5.664 | loss    1.734 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8006it [03:20, 41.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  8000/17123 batches | perplexity    5.552 | loss    1.714 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8508it [03:33, 40.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  8500/17123 batches | perplexity    5.736 | loss    1.747 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9004it [03:45, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  9000/17123 batches | perplexity    5.615 | loss    1.726 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9505it [03:58, 40.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  9500/17123 batches | perplexity    5.643 | loss    1.730 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10009it [04:10, 39.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 10000/17123 batches | perplexity    5.497 | loss    1.704 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10507it [04:23, 39.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 10500/17123 batches | perplexity    5.723 | loss    1.744 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11008it [04:35, 38.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 11000/17123 batches | perplexity    5.642 | loss    1.730 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11507it [04:48, 41.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 11500/17123 batches | perplexity    5.556 | loss    1.715 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12006it [05:01, 39.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 12000/17123 batches | perplexity    5.642 | loss    1.730 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12507it [05:13, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 12500/17123 batches | perplexity    5.566 | loss    1.717 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13007it [05:26, 40.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 13000/17123 batches | perplexity    5.657 | loss    1.733 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13505it [05:38, 40.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 13500/17123 batches | perplexity    5.536 | loss    1.711 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14008it [05:51, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 14000/17123 batches | perplexity    5.773 | loss    1.753 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14505it [06:03, 41.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 14500/17123 batches | perplexity    5.809 | loss    1.759 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15008it [06:16, 39.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 15000/17123 batches | perplexity    5.570 | loss    1.717 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15508it [06:28, 39.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 15500/17123 batches | perplexity    5.420 | loss    1.690 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16005it [06:41, 41.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 16000/17123 batches | perplexity    5.578 | loss    1.719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16508it [06:53, 38.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 16500/17123 batches | perplexity    5.577 | loss    1.719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17008it [07:06, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 | 17000/17123 batches | perplexity    5.691 | loss    1.739 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17123it [07:09, 39.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 431.72s | valid perplexity    5.667 | valid loss    1.735\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "507it [00:12, 41.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |   500/17123 batches | perplexity    5.638 | loss    1.730 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1005it [00:24, 41.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1000/17123 batches | perplexity    5.447 | loss    1.695 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1506it [00:37, 41.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1500/17123 batches | perplexity    5.491 | loss    1.703 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2008it [00:50, 37.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  2000/17123 batches | perplexity    5.610 | loss    1.724 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2509it [01:02, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  2500/17123 batches | perplexity    5.575 | loss    1.718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3008it [01:15, 40.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  3000/17123 batches | perplexity    5.539 | loss    1.712 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3508it [01:27, 40.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  3500/17123 batches | perplexity    5.560 | loss    1.716 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4007it [01:39, 41.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  4000/17123 batches | perplexity    5.855 | loss    1.767 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4507it [01:52, 41.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  4500/17123 batches | perplexity    5.739 | loss    1.747 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5007it [02:04, 40.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  5000/17123 batches | perplexity    5.682 | loss    1.737 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5505it [02:16, 41.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  5500/17123 batches | perplexity    5.761 | loss    1.751 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6005it [02:28, 41.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  6000/17123 batches | perplexity    5.556 | loss    1.715 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6507it [02:41, 41.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  6500/17123 batches | perplexity    5.744 | loss    1.748 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7009it [02:53, 42.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  7000/17123 batches | perplexity    5.628 | loss    1.728 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7507it [03:05, 40.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  7500/17123 batches | perplexity    5.720 | loss    1.744 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8002it [03:18, 24.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  8000/17123 batches | perplexity    5.643 | loss    1.730 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8507it [03:31, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  8500/17123 batches | perplexity    5.640 | loss    1.730 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9006it [03:43, 40.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  9000/17123 batches | perplexity    5.675 | loss    1.736 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9508it [03:56, 39.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  9500/17123 batches | perplexity    5.524 | loss    1.709 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10008it [04:08, 42.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 10000/17123 batches | perplexity    5.602 | loss    1.723 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10506it [04:20, 39.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 10500/17123 batches | perplexity    5.719 | loss    1.744 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11005it [04:34, 37.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 11000/17123 batches | perplexity    5.605 | loss    1.724 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11509it [04:47, 39.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 11500/17123 batches | perplexity    5.576 | loss    1.718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12005it [04:59, 40.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 12000/17123 batches | perplexity    5.661 | loss    1.734 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12508it [05:11, 41.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 12500/17123 batches | perplexity    5.547 | loss    1.713 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13009it [05:24, 42.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 13000/17123 batches | perplexity    5.602 | loss    1.723 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13504it [05:36, 39.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 13500/17123 batches | perplexity    5.615 | loss    1.725 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14005it [05:48, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 14000/17123 batches | perplexity    5.594 | loss    1.722 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14509it [06:01, 41.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 14500/17123 batches | perplexity    5.587 | loss    1.720 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15007it [06:13, 40.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 15000/17123 batches | perplexity    5.615 | loss    1.725 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15506it [06:25, 40.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 15500/17123 batches | perplexity    5.448 | loss    1.695 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16007it [06:38, 39.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 16000/17123 batches | perplexity    5.723 | loss    1.745 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16506it [06:50, 40.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 16500/17123 batches | perplexity    5.615 | loss    1.725 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17006it [07:02, 41.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 | 17000/17123 batches | perplexity    5.668 | loss    1.735 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17123it [07:05, 40.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 428.17s | valid perplexity    5.667 | valid loss    1.735\n",
      "-----------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test perplexity    5.712 | test loss    1.742 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader, model, optimizer, criterion, epoch)\n",
    "    loss_val, perplexity_val = evaluate(validation_dataloader, model, criterion)\n",
    "    scheduler.step()\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} \"\n",
    "        \"| time: {:5.2f}s \"\n",
    "        \"| valid perplexity {:8.3f} \"\n",
    "        \"| valid loss {:8.3f}\".format(\n",
    "            epoch,\n",
    "            time.time() - epoch_start_time,\n",
    "            perplexity_val,\n",
    "            loss_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "print(\"Checking the results of test dataset.\")\n",
    "loss_test, perplexity_test = evaluate(test_dataloader, model, criterion)\n",
    "print(\"test perplexity {:8.3f} | test loss {:8.3f} \".format(perplexity_test, loss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d091ff8",
   "metadata": {},
   "source": [
    "Hint: For the above, you should see your loss around 2.0 and going down. Similarly to perplexity which should be aroud 7 to 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de0230d",
   "metadata": {},
   "source": [
    "## Generate some text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e97642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word(model, dataset, window):\n",
    "    generated_word = []\n",
    "    # Set the context to a window-1 length array having just the MARKER character's token_id.\n",
    "    context = [0] * (n-1)\n",
    "    \n",
    "    while True:\n",
    "        logits = model(torch.tensor(context).view(1, -1))\n",
    "        \n",
    "        # Get the probabilities from the logits.\n",
    "        # Hint: softmax!\n",
    "        softmax = torch.nn.Softmax()\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        # Get 1 sample from a multinomial having the above probabilities.\n",
    "        token_id = torch.multinomial(probs, 1, replacement=True).item()\n",
    "        \n",
    "        # Append the token_id to the generated word.\n",
    "        generated_word.append(token_id)\n",
    "        \n",
    "        # Move the context over 1, drop the first (oldest) token and apped the new one above.\n",
    "        # The size of the resulting context should be the same.\n",
    "        # For exaple, if it was \"[0, 1, 2]\" and you generated 4, it should now be [1, 2, 4].\n",
    "        context = context[1:] + [token_id]\n",
    "        \n",
    "        if token_id == 0:\n",
    "            # If you generate token_id = 0, i.e. '.', break out.\n",
    "            break\n",
    "    # Return and decode the generated word to a string.        \n",
    "    return ''.join(dataset.decode(generated_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "238d0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aka.\n",
      "kamilih.\n",
      "nacdon.\n",
      "nuzorla.\n",
      "zon.\n",
      "jovrayah.\n",
      "calie.\n",
      "rajandhorandu.\n",
      "lydah.\n",
      "jandelaigh.\n",
      "cho.\n",
      "dumiriye.\n",
      "zelise.\n",
      "truya.\n",
      "mereiyanny.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp/ipykernel_6224/2927531224.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beya.\n",
      "kinza.\n",
      "kambrisy.\n",
      "mayah.\n",
      "boria.\n",
      "dalleya.\n",
      "pellia.\n",
      "dhi.\n",
      "amar.\n",
      "ymandilistiee.\n",
      "adanf.\n",
      "damekinzaiy.\n",
      "briel.\n",
      "rirkanie.\n",
      "just.\n",
      "esa.\n",
      "yra.\n",
      "sum.\n",
      "azon.\n",
      "jerison.\n",
      "killa.\n",
      "ell.\n",
      "est.\n",
      "sen.\n",
      "smande.\n",
      "malanna.\n",
      "dakerrishayn.\n",
      "rosy.\n",
      "rynne.\n",
      "mayshantm.\n",
      "caelyliyana.\n",
      "maen.\n",
      "asialarynn.\n",
      "jaiton.\n",
      "rhetly.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "for _ in range(50):\n",
    "    print(generate_word(model, train_dataset, n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
